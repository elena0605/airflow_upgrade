---
title: "YouTube Channel Analysis Report"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: cosmo
    code_folding: hide
    code_menu: true
    df_print: paged
params:
  data_path: NULL
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(knitr)
library(kableExtra)
library(dplyr)
library(ggplot2)
library(corrplot)
library(reshape2)
library(viridis)
library(tidyr)
library(scales)
library(jsonlite)
library(DT)

# Set data path
data_path <- params$data_path
if (is.null(data_path)) {
  # Use absolute path for now
  data_path <- "/Users/bojansimoski/dev/airflow_upgrade/mongodb_scripts/output/youtube"
}

# Ensure data path exists
if (!dir.exists(data_path)) {
  stop("Data path does not exist: ", data_path)
}

print(paste("Loading data from:", data_path))
```

## Intro: YouTube API calls and entity mapping

- YouTubeChannel (channel_basic_statistics.csv)
  - channels.list: `https://www.googleapis.com/youtube/v3/channels?part=statistics,brandingSettings,topicDetails&id={channel_id}&key=API_KEY`
  - Implemented in `get_channels_statistics()`

- YouTubeVideo, YouTubeVideoTag, YouTubeVideoTopic (youtube_videos_flat.csv)
  - search.list (date-bounded pagination): `https://www.googleapis.com/youtube/v3/search?part=snippet&channelId={channel_id}&type=video&order=date&maxResults=50&publishedAfter={start}&publishedBefore={end}&key=API_KEY`
  - videos.list (details in batches of 50): `https://www.googleapis.com/youtube/v3/videos?part=statistics,snippet,topicDetails&id={comma_separated_ids}&key=API_KEY`
  - Implemented in `get_videos_by_date()` and `get_video_details()`

- YouTubeVideoComment (youtube_video_comments_flat.csv)
  - commentThreads.list (top-level comments): `https://www.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId={video_id}&maxResults=100&key=API_KEY`
  - Implemented in `get_top_level_comments()`

- YouTubeVideoReply (youtube_video_replies_flat.csv)
  - comments.list (replies): `https://www.googleapis.com/youtube/v3/comments?part=snippet&parentId={comment_id}&maxResults=100&key=API_KEY`
  - Implemented in `get_replies_for_comment()`

- YouTubeVideoCaption (youtube_video_captions_flat.csv)
  - captions.list: `https://www.googleapis.com/youtube/v3/captions?part=snippet&videoId={video_id}`
  - captions.download: `https://www.googleapis.com/youtube/v3/captions/{caption_id}` (requires OAuth)
  - Implemented in `fetch_youtube_captions()`



## Data Completeness

```{r data-completeness, echo=FALSE}
# Helpers
read_csv_if_exists <- function(path) {
  if (file.exists(path)) read.csv(path, stringsAsFactors = FALSE) else NULL
}

is_missing_val <- function(x) {
  if (is.numeric(x)) return(is.na(x))
  tx <- trimws(as.character(x))
  empty_json_array <- grepl("^\\[\\s*\\]$", tx)
  empty_json_object <- grepl("^\\{\\s*\\}$", tx)
  is.na(tx) | tx == "" | tolower(tx) %in% c("na", "null", "none") | empty_json_array | empty_json_object
}

compute_property_table <- function(entity, df) {
  total <- nrow(df)
  data.frame(
    Entity = entity,
    Property = names(df),
    NonMissing = sapply(df, function(col) sum(!is_missing_val(col))),
    Total = total,
    CompletenessPct = round(100 * sapply(df, function(col) mean(!is_missing_val(col))), 1),
    stringsAsFactors = FALSE
  )
}

# Entities and their CSVs (use available CSVs only)
entities <- list(
  list(title = "YouTubeChannel", csv = "channel_basic_statistics.csv"),
  list(title = "YouTubeVideo", csv = "youtube_videos_flat.csv"),
  list(title = "YouTubeVideoComment", csv = "youtube_video_comments_flat.csv"),
  list(title = "YouTubeVideoReply", csv = "youtube_video_replies_flat.csv"),
  list(title = "YouTubeVideoCaption", csv = "youtube_video_captions_flat.csv"),
  list(title = "Tag", csv = "youtube_video_tags_flat.csv"),
  list(title = "Topic", csv = "youtube_video_topics_flat.csv")
)
# Add captions if present
if (file.exists(file.path(data_path, "youtube_video_captions.csv"))) {
  entities <- c(entities, list(list(title = "YouTubeVideoCaption", csv = "youtube_video_captions.csv")))
}

all_props <- NULL
for (e in entities) {
  path <- file.path(data_path, e$csv)
  df <- read_csv_if_exists(path)
  if (!is.null(df) && nrow(df) > 0) {
    all_props <- rbind(all_props, compute_property_table(e$title, df))
  }
}

cat("### Per-Property Completeness (%)\\n\\n")
if (is.null(all_props)) {
  cat("No data available for completeness calculations.\\n")
} else {
  all_props <- all_props[order(all_props$Entity, -all_props$CompletenessPct, all_props$Property), ]
  DT::datatable(
    all_props,
    options = list(scrollX = TRUE, pageLength = 25, order = list(list(0, 'asc'), list(4, 'desc'))),
    rownames = FALSE,
    caption = "Per-property completeness across YouTube entities"
  )
}
```

## Executive Summary

This report provides a comprehensive analysis of YouTube channel data, examining channel performance, content characteristics, and engagement patterns. The analysis covers multiple dimensions including subscriber metrics, video performance, channel statistics, and geographic distribution.

### Data Overview

```{r data-overview, echo=FALSE}
# Load basic statistics
if (file.exists(file.path(data_path, "channel_basic_statistics.csv"))) {
  channel_data <- read.csv(file.path(data_path, "channel_basic_statistics.csv"))
  total_channels <- nrow(channel_data)
  cat("**Total YouTube Channels Analyzed**:", total_channels, "\n")
} else {
  cat("Channel data not found\n")
}

# Load video statistics
if (file.exists(file.path(data_path, "channel_video_statistics.csv"))) {
  video_stats <- read.csv(file.path(data_path, "channel_video_statistics.csv"))
  if (nrow(video_stats) > 0) {
    total_videos <- video_stats$totalVideos[1]
    unique_channels <- video_stats$uniqueChannels[1]
    cat("**Total Videos Analyzed**:", total_videos, "\n")
    cat("**Channels with Video Data**:", unique_channels, "\n")
  }
}

# Load country data
if (file.exists(file.path(data_path, "channel_by_country.csv"))) {
  country_data <- read.csv(file.path(data_path, "channel_by_country.csv"))
  total_countries <- nrow(country_data)
  cat("**Countries Represented**:", total_countries, "\n")
}
```

## 1. Channel Performance Analysis

### Basic Channel Statistics

```{r channel-stats, echo=FALSE}
if (file.exists(file.path(data_path, "channel_basic_statistics.csv"))) {
  channel_data <- read.csv(file.path(data_path, "channel_basic_statistics.csv"))
  
  # Ensure numeric columns are properly formatted
  # Handle both old format (Videos) and new format (TotalVideos, CollectedVideos)
  if ("TotalVideos" %in% names(channel_data) && "CollectedVideos" %in% names(channel_data)) {
    # New format with TotalVideos and CollectedVideos
    channel_data <- channel_data %>%
      mutate(
        Views = as.numeric(Views),
        Subscribers = as.numeric(Subscribers),
        TotalVideos = as.numeric(TotalVideos),
        CollectedVideos = as.numeric(CollectedVideos),
        Views.Per.Video = as.numeric(Views.Per.Video),
        Views.Per.Subscriber = as.numeric(Views.Per.Subscriber)
      )
  } else if ("Videos" %in% names(channel_data)) {
    # Old format - convert Videos to TotalVideos and CollectedVideos
    channel_data <- channel_data %>%
      mutate(
        Views = as.numeric(Views),
        Subscribers = as.numeric(Subscribers),
        TotalVideos = as.numeric(Videos),
        CollectedVideos = as.numeric(Videos),  # Use same value if CollectedVideos not available
        Views.Per.Video = as.numeric(Views.Per.Video),
        Views.Per.Subscriber = as.numeric(Views.Per.Subscriber)
      )
  }
  
  # Calculate summary statistics with proper formatting
  channel_summary <- channel_data %>%
    summarise(
      `Total Channels` = n(),
      `Mean Views` = round(mean(Views, na.rm = TRUE), 0),
      `Median Views` = round(median(Views, na.rm = TRUE), 0),
      `Max Views` = max(Views, na.rm = TRUE),
      `Mean Subscribers` = round(mean(Subscribers, na.rm = TRUE), 0),
      `Median Subscribers` = round(median(Subscribers, na.rm = TRUE), 0),
      `Max Subscribers` = max(Subscribers, na.rm = TRUE),
      `Mean Total Videos` = round(mean(TotalVideos, na.rm = TRUE), 1),
      `Mean Collected Videos` = round(mean(CollectedVideos, na.rm = TRUE), 1),
      `Median Total Videos` = round(median(TotalVideos, na.rm = TRUE), 1),
      `Median Collected Videos` = round(median(CollectedVideos, na.rm = TRUE), 1)
    )
  
  # Format summary numbers with commas (no scientific notation)
  channel_summary_formatted <- channel_summary %>%
    mutate(
      `Mean Views` = format(`Mean Views`, big.mark = ",", scientific = FALSE),
      `Median Views` = format(`Median Views`, big.mark = ",", scientific = FALSE),
      `Max Views` = format(`Max Views`, big.mark = ",", scientific = FALSE),
      `Mean Subscribers` = format(`Mean Subscribers`, big.mark = ",", scientific = FALSE),
      `Median Subscribers` = format(`Median Subscribers`, big.mark = ",", scientific = FALSE),
      `Max Subscribers` = format(`Max Subscribers`, big.mark = ",", scientific = FALSE)
    )
  
  kable(channel_summary_formatted, caption = "Channel Statistics Summary")
  
  # Prepare all channels data for scrollable table
  # Sort first, then format for display
  all_channels_data <- channel_data %>%
    arrange(desc(Subscribers)) %>%
    mutate(
      Views = format(Views, big.mark = ",", scientific = FALSE),
      Subscribers = format(Subscribers, big.mark = ",", scientific = FALSE),
      TotalVideos = format(TotalVideos, big.mark = ",", scientific = FALSE),
      CollectedVideos = format(CollectedVideos, big.mark = ",", scientific = FALSE),
      Views.Per.Video = format(round(Views.Per.Video, 2), big.mark = ",", scientific = FALSE),
      Views.Per.Subscriber = format(round(Views.Per.Subscriber, 2), big.mark = ",", scientific = FALSE)
    ) %>%
    select(Channel, Views, Subscribers, TotalVideos, CollectedVideos, Views.Per.Video, Views.Per.Subscriber)
  
  # Create scrollable table with all channels
  cat("\n### All Channels Analyzed\n\n")
  DT::datatable(
    all_channels_data,
    caption = "Channels by Subscriber Count",
    options = list(
      scrollX = TRUE,
      scrollY = "500px",
      pageLength = 50,
      searching = TRUE,
      order = list(list(2, 'desc'))  # Sort by Subscribers descending (column index 2)
    ),
    rownames = FALSE
  )
  
  
} else {
  cat("Channel statistics data not available\n")
}
```

### Channel Performance Visualization

```{r channel-performance-plot, echo=FALSE}
if (file.exists(file.path(data_path, "channel_basic_statistics.csv"))) {
  channel_data <- read.csv(file.path(data_path, "channel_basic_statistics.csv"))
  
  # Handle both old format (Videos) and new format (TotalVideos, CollectedVideos)
  if ("CollectedVideos" %in% names(channel_data)) {
    video_col <- "CollectedVideos"
  } else if ("Videos" %in% names(channel_data)) {
    video_col <- "Videos"
  } else {
    video_col <- "TotalVideos"
  }
  
  channel_data <- channel_data %>%
    mutate(
      Views = as.numeric(Views),
      Subscribers = as.numeric(Subscribers),
      VideoCount = as.numeric(!!sym(video_col))
    )
  
  # Create scatter plot of subscribers vs views
  performance_plot <- ggplot(channel_data, aes(x = Subscribers, y = Views, size = VideoCount)) +
    geom_point(alpha = 0.6, color = "steelblue") +
    scale_x_log10(labels = comma_format()) +
    scale_y_log10(labels = comma_format()) +
    scale_size_continuous(name = "Collected Videos", range = c(1, 8)) +
    labs(
      title = "Channel Performance: Subscribers vs Views",
      subtitle = "Bubble size represents collected video count (2023)",
      x = "Subscribers (log scale)",
      y = "Total Views (log scale)"
    ) +
    theme_minimal(base_size = 12) +
    theme(
      plot.title = element_text(face = "bold", size = 16, hjust = 0.5),
      plot.subtitle = element_text(size = 12, hjust = 0.5)
    )
  
  print(performance_plot)
} else {
  cat("Channel data not available for visualization\n")
}
```

### Collected Videos Distribution

```{r collected-videos-histogram, echo=FALSE}
if (file.exists(file.path(data_path, "channel_basic_statistics.csv"))) {
  channel_data <- read.csv(file.path(data_path, "channel_basic_statistics.csv"))
  
  # Handle both old format (Videos) and new format (TotalVideos, CollectedVideos)
  if ("CollectedVideos" %in% names(channel_data)) {
    video_col <- "CollectedVideos"
  } else if ("Videos" %in% names(channel_data)) {
    video_col <- "Videos"
  } else {
    video_col <- "TotalVideos"
  }
  
  channel_data <- channel_data %>%
    mutate(
      VideoCount = as.numeric(!!sym(video_col))
    )

  # Full dataset (includes zeros) and filtered dataset (>0) for histogram only
  channel_data_full <- channel_data
  channel_data <- channel_data_full %>%
    filter(!is.na(VideoCount) & VideoCount > 0)
  
  if (nrow(channel_data) > 0) {
    # Original simple histogram: 30 bins, no labels, default ticks
    histogram_plot <- ggplot(channel_data, aes(x = VideoCount)) +
      geom_histogram(bins = 30, fill = "steelblue", color = "white", alpha = 0.7) +
      scale_x_continuous(labels = comma_format()) +
      scale_y_continuous(labels = comma_format()) +
      labs(
        title = "Distribution of Collected Videos per Channel",
        subtitle = "Histogram showing the number of videos collected from each channel (2023 data)",
        x = "Number of Collected Videos",
        y = "Number of Channels",
        caption = paste("Total channels:", nrow(channel_data_full), "| Mean:", round(mean(channel_data_full$VideoCount, na.rm = TRUE), 1), "videos")
      ) +
      theme_minimal(base_size = 12) +
      theme(
        plot.title = element_text(face = "bold", size = 16, hjust = 0.5),
        plot.subtitle = element_text(size = 12, hjust = 0.5),
        plot.caption = element_text(size = 10, hjust = 0.5, margin = margin(t = 10))
      )
    
    print(histogram_plot)
    
    # Summary statistics
    cat("\n**Summary Statistics for Collected Videos:**\n")
    cat("- Mean:", round(mean(channel_data_full$VideoCount, na.rm = TRUE), 1), "videos\n")
    cat("- Median:", round(median(channel_data_full$VideoCount, na.rm = TRUE), 1), "videos\n")
    cat("- Max:", max(channel_data_full$VideoCount, na.rm = TRUE), "videos\n")
    cat("- Min:", min(channel_data_full$VideoCount, na.rm = TRUE), "videos\n")
    
    # Use full dataset (including zeros) for the listings below
    # (channel_data_full already available)
    
    # Channels with 0 videos
    channels_zero <- channel_data_full %>%
      filter(VideoCount == 0) %>%
      select(Channel, matches("TotalVideos|CollectedVideos|Videos")) %>%
      arrange(Channel)
    
    # Channels with 1-10 videos
    channels_1_10 <- channel_data_full %>%
      filter(VideoCount >= 1 & VideoCount <= 10) %>%
      arrange(VideoCount, Channel)
    
    # (Lists/tables removed as per request)
  }
} else {
  cat("Channel data not available for histogram\n")
}
```

## 2. Tag and Topic Frequencies

```{r tag-topic-frequencies-after, echo=FALSE}
read_if <- function(p) if (file.exists(p)) read.csv(p, stringsAsFactors = FALSE) else NULL

# Tags
tags_unique <- read_if(file.path(data_path, "youtube_video_tags_unique.csv"))
if (!is.null(tags_unique)) {
  kable(head(tags_unique, 50), caption = "Top 50 Tags by Occurrence")
}

# Topics
topics_unique <- read_if(file.path(data_path, "youtube_video_topics_unique.csv"))
if (!is.null(topics_unique)) {
  kable(head(topics_unique, 50), caption = "Top 50 Topics by Occurrence")
}
```
### Channel Distribution by Topic Category

```{r topic-category-analysis, echo=FALSE}
# Use per-video topics unique counts to align with Top 50 Topics
unique_topics_path <- file.path(data_path, "youtube_video_topics_unique.csv")
if (file.exists(unique_topics_path)) {
  topic_unique <- read.csv(unique_topics_path, stringsAsFactors = FALSE)
  # Human-readable category name from URL-like strings
  topic_unique <- topic_unique %>%
    mutate(
      category_name = gsub(".*/", "", topic_category),
      category_name = gsub("_", " ", category_name),
      category_name = tools::toTitleCase(category_name)
    )
  
  # Top 10 by distinct channels to represent breadth
  top_categories <- topic_unique %>%
    arrange(desc(distinct_channels)) %>%
    head(10)
  
  category_plot <- ggplot(top_categories, aes(x = reorder(category_name, distinct_channels), y = distinct_channels, fill = category_name)) +
    geom_col(alpha = 0.8) +
    geom_text(aes(label = distinct_channels), hjust = -0.1, size = 3.5, fontface = "bold") +
    scale_fill_viridis_d() +
    coord_flip() +
    labs(
      title = "Top 10 Categories by Distinct Channels",
      subtitle = "Using per-video topics (2023 data)",
      x = "Category",
      y = "Distinct Channels",
      fill = "Category"
    ) +
    theme_minimal(base_size = 12) +
    theme(
      plot.title = element_text(face = "bold", size = 16, hjust = 0.5),
      plot.subtitle = element_text(size = 12, hjust = 0.5),
      legend.position = "none"
    ) +
    scale_y_continuous(expand = expansion(mult = c(0, 0.1)))
  
  print(category_plot)
} else {
  cat("Topic category data (unique) not available\n")
}
```

### Category Performance Metrics

```{r category-performance, echo=FALSE}
# Join per-video topics to per-video stats to compute performance by topic
topics_flat_path <- file.path(data_path, "youtube_video_topics_flat.csv")
videos_flat_path <- file.path(data_path, "youtube_videos_flat.csv")
if (file.exists(topics_flat_path) && file.exists(videos_flat_path)) {
  topics_flat <- read.csv(topics_flat_path, stringsAsFactors = FALSE)
  videos_flat <- read.csv(videos_flat_path, stringsAsFactors = FALSE) %>%
    select(video_id, view_count)
  
  topic_videos <- topics_flat %>%
    inner_join(videos_flat, by = "video_id") %>%
    mutate(
      category_name = gsub(".*/", "", topic_category),
      category_name = gsub("_", " ", category_name),
      category_name = tools::toTitleCase(category_name),
      view_count = suppressWarnings(as.numeric(view_count))
    )
  
  perf <- topic_videos %>%
    group_by(category_name) %>%
    summarise(
      Videos = n(),
      Distinct_Channels = n_distinct(channel_id),
      Total_Views = round(sum(view_count, na.rm = TRUE), 0),
      Avg_Views_Per_Video = round(mean(view_count, na.rm = TRUE), 0),
      .groups = "drop"
    ) %>%
    arrange(desc(Videos)) %>%
    head(10)
  
  perf <- perf %>%
    mutate(
      Total_Views = format(Total_Views, big.mark = ",", scientific = FALSE),
      Avg_Views_Per_Video = format(Avg_Views_Per_Video, big.mark = ",", scientific = FALSE)
    )
  
  kable(perf, caption = "Category Performance (Top 10 by Videos)")
} else {
  cat("Topic performance data not available\n")
}
```


## 3. Geographic Distribution Analysis

### Channel Distribution by Country

```{r country-analysis, echo=FALSE}
if (file.exists(file.path(data_path, "channel_by_country.csv"))) {
  country_data <- read.csv(file.path(data_path, "channel_by_country.csv"))
  
  # Top 10 countries by channel count
  top_countries <- country_data %>%
    arrange(desc(Channel.Count)) %>%
    head(10)
  
  # Create visualization
  country_plot <- ggplot(top_countries, aes(x = reorder(Country, Channel.Count), y = Channel.Count, fill = Country)) +
    geom_col(alpha = 0.8) +
    geom_text(aes(label = Channel.Count), hjust = -0.1, size = 3.5, fontface = "bold") +
    scale_fill_viridis_d() +
    coord_flip() +
    labs(
      title = "Top 10 Countries by Channel Count",
      subtitle = "Geographic distribution of YouTube channels",
      x = "Country",
      y = "Number of Channels",
      fill = "Country"
    ) +
    theme_minimal(base_size = 12) +
    theme(
      plot.title = element_text(face = "bold", size = 16, hjust = 0.5),
      plot.subtitle = element_text(size = 12, hjust = 0.5),
      legend.position = "none"
    ) +
    scale_y_continuous(expand = expansion(mult = c(0, 0.1)))
  
  print(country_plot)
  
  
} else {
  cat("Country data not available\n")
}
```

### Channel Performance by Country

```{r country-performance, echo=FALSE}
if (file.exists(file.path(data_path, "channel_by_country.csv"))) {
  country_data <- read.csv(file.path(data_path, "channel_by_country.csv"))
  
  # Calculate average metrics by country
  country_metrics <- country_data %>%
    mutate(
      Avg_Views = round(Total.Views / Channel.Count, 0),
      Avg_Subscribers = round(Total.Subscribers / Channel.Count, 0)
    ) %>%
    arrange(desc(Channel.Count)) %>%
    head(10) %>%
    select(Country, Channel.Count, Avg_Views, Avg_Subscribers)
  
  kable(country_metrics, caption = "Average Channel Performance by Country (Top 10)")
} else {
  cat("Country performance data not available\n")
}
```



## 4. Video Content Analysis

### Channel Video Statistics

```{r video-stats-analysis, echo=FALSE}
if (file.exists(file.path(data_path, "channel_video_statistics.csv"))) {
  video_stats <- read.csv(file.path(data_path, "channel_video_statistics.csv"))
  
  # Extract key metrics
  if (nrow(video_stats) > 0) {
    stats_summary <- data.frame(
      Metric = c("Total Videos", "Unique Channels", "Channels with Exact Match", "Channels with Trimmed Match", "Channels with No Match"),
      Value = c(
        video_stats$totalVideos[1],
        video_stats$uniqueChannels[1],
        video_stats$channelsWithExactMatch[1],
        video_stats$channelsWithTrimmedMatch[1],
        video_stats$channelsWithNoMatch[1]
      )
    )
    
    kable(stats_summary, caption = "Video Statistics Summary")
    
    # Calculate percentages
    total_channels <- video_stats$uniqueChannels[1]
    
    # Handle non-numeric values in CSV
    exact_match <- as.numeric(video_stats$channelsWithExactMatch[1])
    trimmed_match <- as.numeric(video_stats$channelsWithTrimmedMatch[1])
    no_match <- as.numeric(video_stats$channelsWithNoMatch[1])
    
    # Replace NA values with 0
    exact_match <- ifelse(is.na(exact_match), 0, exact_match)
    trimmed_match <- ifelse(is.na(trimmed_match), 0, trimmed_match)
    no_match <- ifelse(is.na(no_match), 0, no_match)
    
    exact_match_pct <- round(exact_match / total_channels * 100, 1)
    trimmed_match_pct <- round(trimmed_match / total_channels * 100, 1)
    no_match_pct <- round(no_match / total_channels * 100, 1)
    
    cat("**Data Quality Metrics:**\n")
    cat("- Exact Match:", exact_match_pct, "%\n")
    cat("- Trimmed Match:", trimmed_match_pct, "%\n")
    cat("- No Match:", no_match_pct, "%\n")
  }
} else {
  cat("Video statistics data not available\n")
}
```

### Video Comments Analysis

```{r comments-analysis, echo=FALSE}
if (file.exists(file.path(data_path, "video_comments_stats.csv"))) {
  comments_data <- read.csv(file.path(data_path, "video_comments_stats.csv"))
  
  # Parse JSON data from comments_stats column
  if (nrow(comments_data) > 0 && "comments_stats" %in% names(comments_data)) {
    # Extract data from JSON
    comments_stats <- comments_data$comments_stats[1]
    if (!is.na(comments_stats) && comments_stats != "") {
      # Parse the JSON string
      stats_json <- jsonlite::fromJSON(comments_stats)
      
      cat("**Comments Analysis Summary:**\n")
      cat("- Total Videos with Comments:", stats_json$total_videos_with_comments, "\n")
      cat("- Total Comments:", stats_json$total_comments, "\n")
      cat("- Total Likes:", stats_json$total_likes, "\n")
      cat("- Total Replies:", stats_json$total_replies, "\n")
      cat("- Average Comments per Video:", stats_json$comments_per_video$avg, "\n")
      cat("- Average Likes per Video:", stats_json$likes_per_video$avg, "\n")
      cat("- Average Replies per Video:", stats_json$replies_per_video$avg, "\n")
      cat("- Likes per Comment:", stats_json$engagement_metrics$likes_per_comment, "\n")
      cat("- Replies per Comment:", stats_json$engagement_metrics$replies_per_comment, "\n")
    } else {
      cat("Comments data not available\n")
    }
  } else {
    cat("Comments data not available\n")
  }
} else {
  cat("Comments data not available\n")
}
```

### Video Replies Analysis

```{r replies-analysis, echo=FALSE}
if (file.exists(file.path(data_path, "video_replies_stats.csv"))) {
  replies_data <- read.csv(file.path(data_path, "video_replies_stats.csv"))
  
  # Parse JSON data from replies_stats column
  if (nrow(replies_data) > 0 && "replies_stats" %in% names(replies_data)) {
    # Extract data from JSON
    replies_stats <- replies_data$replies_stats[1]
    if (!is.na(replies_stats) && replies_stats != "") {
      # Parse the JSON string
      stats_json <- jsonlite::fromJSON(replies_stats)
      
      cat("**Replies Analysis Summary:**\n")
      cat("- Total Videos with Replies:", stats_json$total_videos_with_replies, "\n")
      cat("- Total Replies:", stats_json$total_replies, "\n")
      cat("- Total Likes on Replies:", stats_json$total_likes_on_replies, "\n")
      cat("- Average Replies per Video:", stats_json$replies_per_video$avg, "\n")
      cat("- Average Likes per Reply:", stats_json$likes_per_reply$avg, "\n")
    } else {
      cat("Replies data not available\n")
    }
  } else {
    cat("Replies data not available\n")
  }
} else {
  cat("Replies data not available\n")
}
```

<!-- ## 6. Data Quality Analysis (removed) -->

```{r empty-fields-analysis, echo=FALSE, eval=FALSE, include=FALSE}
if (file.exists(file.path(data_path, "channel_empty_fields.csv"))) {
  empty_fields_data <- read.csv(file.path(data_path, "channel_empty_fields.csv"))
  
  if (nrow(empty_fields_data) > 0) {
    cat("**Channel Empty Fields Analysis:**\n")
    cat("- Total Channels with Empty Fields:", nrow(empty_fields_data), "\n")
    
    # Show first few channels with empty fields
    if (nrow(empty_fields_data) > 0) {
      cat("\n**Sample Channels with Empty Fields:**\n")
      for (i in 1:min(5, nrow(empty_fields_data))) {
        cat("-", empty_fields_data$Channel[i], ":", empty_fields_data$Empty.Fields[i], "\n")
      }
    }
  } else {
    cat("No empty fields data available\n")
  }
} else {
  cat("Empty fields data not available\n")
}
```

```{r video-empty-fields, echo=FALSE, eval=FALSE, include=FALSE}
if (file.exists(file.path(data_path, "channel_video_empty_fields.csv"))) {
  video_empty_data <- read.csv(file.path(data_path, "channel_video_empty_fields.csv"))
  
  if (nrow(video_empty_data) > 0) {
    cat("**Video Empty Fields Analysis:**\n")
    cat("- Total Videos Analyzed:", video_empty_data$totalDocuments[1], "\n")
    
    # Parse field analysis if available
    if ("fieldAnalysis" %in% names(video_empty_data) && !is.na(video_empty_data$fieldAnalysis[1])) {
      cat("- Field Analysis:", video_empty_data$fieldAnalysis[1], "\n")
    }
  } else {
    cat("No video empty fields data available\n")
  }
} else {
  cat("Video empty fields data not available\n")
}
```

<!-- ## 7. Channel Descriptions Analysis (removed) -->

```{r descriptions-analysis, echo=FALSE, eval=FALSE, include=FALSE}
if (file.exists(file.path(data_path, "user_descriptions.csv"))) {
  descriptions_data <- read.csv(file.path(data_path, "user_descriptions.csv"))
  
  cat("**Total Channels with Descriptions**:", nrow(descriptions_data), "\n")
  
  # Sample of descriptions
  sample_descriptions <- descriptions_data %>%
    head(5) %>%
    select(username, description)
  
  kable(sample_descriptions, caption = "Sample Channel Descriptions")
} else {
  cat("Channel descriptions data not available\n")
}
```

<!-- ## 8. Performance Insights (removed) -->

```{r performance-distribution, echo=FALSE, eval=FALSE, include=FALSE}
if (file.exists(file.path(data_path, "channel_basic_statistics.csv"))) {
  channel_data <- read.csv(file.path(data_path, "channel_basic_statistics.csv"))
  
  # Create performance categories
  performance_categories <- channel_data %>%
    mutate(
      Subscriber_Category = case_when(
        Subscribers >= 1000000 ~ "1M+",
        Subscribers >= 100000 ~ "100K-1M",
        Subscribers >= 10000 ~ "10K-100K",
        Subscribers >= 1000 ~ "1K-10K",
        TRUE ~ "Under 1K"
      ),
      Views_Category = case_when(
        Views >= 10000000 ~ "10M+",
        Views >= 1000000 ~ "1M-10M",
        Views >= 100000 ~ "100K-1M",
        Views >= 10000 ~ "10K-100K",
        TRUE ~ "Under 10K"
      )
    )
  
  # Subscriber distribution
  sub_dist <- performance_categories %>%
    count(Subscriber_Category) %>%
    mutate(Percentage = round(n / sum(n) * 100, 1)) %>%
    arrange(factor(Subscriber_Category, levels = c("1M+", "100K-1M", "10K-100K", "1K-10K", "Under 1K")))
  
  kable(sub_dist, caption = "Channel Distribution by Subscriber Count")
  
  # Views distribution
  views_dist <- performance_categories %>%
    count(Views_Category) %>%
    mutate(Percentage = round(n / sum(n) * 100, 1)) %>%
    arrange(factor(Views_Category, levels = c("10M+", "1M-10M", "100K-1M", "10K-100K", "Under 10K")))
  
  kable(views_dist, caption = "Channel Distribution by Total Views")
} else {
  cat("Channel data not available for performance distribution\n")
}
```

<!-- ## 9. Data Quality and Methodology (removed) -->
