---
title: "TikTok Influencer Analysis Report"
author: "Data Analysis Team"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: cosmo
    code_folding: hide
    code_menu: true
params:
  data_path: NULL
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(ggplot2)
library(dplyr)
library(knitr)
library(DT)
library(plotly)
library(reshape2)
library(viridis)
library(tidyr)
library(scales)

# Set data path
data_path <- params$data_path
if (is.null(data_path)) {
  # Use absolute path
  data_path <- "/Users/bojansimoski/dev/airflow_upgrade/mongodb_scripts/output/tiktok"
}

# Ensure data path exists
if (!dir.exists(data_path)) {
  stop("Data path does not exist: ", data_path)
}

print(paste("Loading data from:", data_path))
```

## Intro: TikTok data collection and entity mapping

- TikTokUser (`TikTokUser` node; collection: `tiktok_user_info`)
  - Collected via user profile fetch in the ETL (see `dags/tiktok_dag.py` → MERGE `TikTokUser` with display_name, bio, avatar, counters)
  - Report CSVs used: `followers_count.csv`, `likes_count.csv`, `user_verification.csv`, `user_bios.csv`

- TikTokVideo (`TikTokVideo` node; collection: `tiktok_videos`)
  - Collected via channel/user video listing + detail enrich (see `dags/tiktok_video_dag.py` → MERGE `TikTokVideo` with counts, duration, labels, tags)
  - Report CSVs used: `user_video_duration.csv`, `user_videos_additional_analysis.csv`, `video_field_presence_stats.csv`, `user_videos_comprehensive_analysis.csv`

- TikTokComment (`TikTokComment` node; collection: `tiktok_video_comments`)
  - Collected via video comments fetch (see `dags/tiktok_video_comments_dag.py` → MERGE `TikTokComment` and link to `TikTokVideo`)
  - Report CSVs used: `video_comments_stats.csv` (to be refined)

- TikTokHashtag (`Hashtag` node)
  - Extracted from `TikTokVideo` hashtags and linked with `HAS_HASHTAG` (`dags/tiktok_video_dag.py`)

- TikTokSticker (`Sticker` node)
  - Extracted from `TikTokVideo` stickers and linked with `HAS_STICKER` (`dags/tiktok_video_dag.py`)

## Data Completeness

```{r tiktok-data-completeness, echo=FALSE}
# Helpers
read_csv_if_exists <- function(path) {
  if (file.exists(path)) read.csv(path, stringsAsFactors = FALSE) else NULL
}

is_missing_val <- function(x) {
  if (is.numeric(x)) return(is.na(x))
  tx <- trimws(as.character(x))
  empty_json_array <- grepl("^\\[\\s*\\]$", tx)
  empty_json_object <- grepl("^\\{\\s*\\}$", tx)
  is.na(tx) | tx == "" | tolower(tx) %in% c("na", "null", "none") | empty_json_array | empty_json_object
}

compute_property_table <- function(entity, df) {
  total <- nrow(df)
  data.frame(
    Entity = entity,
    Property = names(df),
    NonMissing = sapply(df, function(col) sum(!is_missing_val(col))),
    Total = total,
    CompletenessPct = round(100 * sapply(df, function(col) mean(!is_missing_val(col))), 1),
    stringsAsFactors = FALSE
  )
}

# Entities and their CSVs (use available CSVs only)
entities <- list(
  list(title = "TikTokUser", csv = "tiktok_users_flat.csv"),
  list(title = "TikTokVideo", csv = "tiktok_videos_flat.csv"),
  list(title = "TikTokComment", csv = "tiktok_video_comments_flat.csv"),
  list(title = "TikTokHashtag", csv = "tiktok_video_hashtags_flat.csv"),
  list(title = "TikTokSticker", csv = "tiktok_video_stickers_flat.csv")
)

all_props <- NULL
for (e in entities) {
  path <- file.path(data_path, e$csv)
  df <- read_csv_if_exists(path)
  if (!is.null(df) && nrow(df) > 0) {
    all_props <- rbind(all_props, compute_property_table(e$title, df))
  }
}

cat("### Per-Property Completeness (%)\n\n")
if (is.null(all_props)) {
  cat("No data available for completeness calculations.\n")
} else {
  all_props <- all_props[order(all_props$Entity, -all_props$CompletenessPct, all_props$Property), ]
  DT::datatable(
    all_props,
    options = list(scrollX = TRUE, pageLength = 25, order = list(list(0, 'asc'), list(4, 'desc'))),
    rownames = FALSE,
    caption = "Per-property completeness across TikTok entities"
  )
}
```
## Executive Summary

This report provides a comprehensive analysis of TikTok influencer data, examining user engagement patterns, content characteristics, and platform dynamics. The analysis covers multiple dimensions including follower metrics, content performance, user verification status, and engagement rates.

### Data Overview

```{r data-overview, echo=FALSE}
# Load basic statistics
if (file.exists(file.path(data_path, "followers_count.csv"))) {
  followers_data <- read.csv(file.path(data_path, "followers_count.csv"))
  total_users <- nrow(followers_data)
  cat("**Total TikTok Users Analyzed**:", total_users, "\n")
} else {
  cat("Followers data not found\n")
}

# Load verification data
if (file.exists(file.path(data_path, "user_verification.csv"))) {
  verification_data <- read.csv(file.path(data_path, "user_verification.csv"))
  if (nrow(verification_data) > 0) {
    verified_count <- verification_data$Count[verification_data$Status == "Verified"]
    if (length(verified_count) > 0) {
      cat("**Verified Users**:", verified_count, "\n")
    }
  }
} else {
  cat("Verification data not available\n")
}
```

## 1. User Engagement Analysis

### Follower Distribution

```{r followers-analysis, echo=FALSE}
if (file.exists(file.path(data_path, "followers_count.csv"))) {
  followers_data <- read.csv(file.path(data_path, "followers_count.csv"))
  
  # Create follower distribution plot
  p1 <- ggplot(followers_data, aes(x = follower_count)) +
    geom_histogram(bins = 30, fill = "steelblue", alpha = 0.7) +
    scale_x_log10(labels = comma_format()) +
    labs(title = "Distribution of Follower Counts",
         x = "Follower Count (log scale)",
         y = "Number of Users") +
    theme_minimal()
  
  print(p1)
  
  # Summary statistics
  cat("**Follower Count Statistics:**\n")
  cat("- Mean:", format(mean(followers_data$follower_count), big.mark = ","), "\n")
  cat("- Median:", format(median(followers_data$follower_count), big.mark = ","), "\n")
  cat("- Max:", format(max(followers_data$follower_count), big.mark = ","), "\n")
  cat("- Min:", format(min(followers_data$follower_count), big.mark = ","), "\n")
  
} else {
  cat("Followers data not available\n")
}
```

### Likes Analysis

```{r likes-analysis, echo=FALSE}
if (file.exists(file.path(data_path, "likes_count.csv"))) {
  likes_data <- read.csv(file.path(data_path, "likes_count.csv"))
  
  # Create likes distribution plot
  p2 <- ggplot(likes_data, aes(x = likes_count)) +
    geom_histogram(bins = 30, fill = "coral", alpha = 0.7) +
    scale_x_log10(labels = comma_format()) +
    labs(title = "Distribution of Likes Counts",
         x = "Likes Count (log scale)",
         y = "Number of Users") +
    theme_minimal()
  
  print(p2)
  
  # Summary statistics
  cat("**Likes Count Statistics:**\n")
  cat("- Mean:", format(mean(likes_data$likes_count), big.mark = ","), "\n")
  cat("- Median:", format(median(likes_data$likes_count), big.mark = ","), "\n")
  cat("- Max:", format(max(likes_data$likes_count), big.mark = ","), "\n")
  cat("- Min:", format(min(likes_data$likes_count), big.mark = ","), "\n")
  
} else {
  cat("Likes data not available\n")
}
```

## 2. User Verification Status

```{r verification-analysis, echo=FALSE}
if (file.exists(file.path(data_path, "user_verification.csv"))) {
  verification_data <- read.csv(file.path(data_path, "user_verification.csv"))
  
  if (nrow(verification_data) > 0) {
    # Create data frame for pie chart
    pie_data <- data.frame(
      Status = c("Verified", "Non-Verified"),
      Count = c(verification_data$Verified.Count, verification_data$Non.Verified.Count)
    )
    
    # Create verification pie chart
    p3 <- ggplot(pie_data, aes(x = "", y = Count, fill = Status)) +
      geom_bar(stat = "identity", width = 1) +
      coord_polar("y", start = 0) +
      labs(title = "User Verification Status Distribution",
           fill = "Status") +
      theme_void() +
      scale_fill_viridis_d()
    
    print(p3)
    
    # Display verification summary
    cat("**Verification Summary:**\n")
    cat("- Verified Users:", verification_data$Verified.Count, "(", round(verification_data$Verified.Percentage, 1), "%)\n")
    cat("- Non-Verified Users:", verification_data$Non.Verified.Count, "(", round(verification_data$Non.Verified.Percentage, 1), "%)\n")
  }
} else {
  cat("Verification data not available\n")
}
```

## 3. Video Duration Analysis

```{r video-duration-analysis, echo=FALSE}
# Prefer per-user counts computed from TikTokVideo flat CSV
videos_flat_path <- file.path(data_path, "tiktok_videos_flat.csv")
if (file.exists(videos_flat_path)) {
  videos_flat <- read.csv(videos_flat_path, stringsAsFactors = FALSE)
  per_user <- videos_flat %>%
    group_by(username) %>%
    summarise(total_videos = dplyr::n(), .groups = "drop")
  
  p4 <- ggplot(per_user, aes(x = total_videos)) +
    geom_histogram(bins = 30, fill = "lightgreen", alpha = 0.7) +
    labs(title = "Distribution of Total Videos per User (from TikTokVideo)",
         x = "Total Videos",
         y = "Number of Users") +
    theme_minimal()
  print(p4)
  
  cat("**Video Statistics (from TikTokVideo):**\n")
  cat("- Mean Videos per User:", round(mean(per_user$total_videos, na.rm = TRUE), 2), "\n")
  cat("- Median Videos per User:", round(median(per_user$total_videos, na.rm = TRUE), 2), "\n")
  cat("- Max Videos per User:", max(per_user$total_videos, na.rm = TRUE), "\n")
  cat("- Min Videos per User:", min(per_user$total_videos, na.rm = TRUE), "\n")
} else if (file.exists(file.path(data_path, "user_video_duration.csv"))) {
  duration_data <- read.csv(file.path(data_path, "user_video_duration.csv"))
  p4 <- ggplot(duration_data, aes(x = total_videos)) +
    geom_histogram(bins = 30, fill = "lightgreen", alpha = 0.7) +
    labs(title = "Distribution of Total Videos per User",
         x = "Total Videos",
         y = "Number of Users") +
    theme_minimal()
  print(p4)
  cat("**Video Statistics:**\n")
  cat("- Mean Videos per User:", round(mean(duration_data$total_videos, na.rm = TRUE), 2), "\n")
  cat("- Median Videos per User:", round(median(duration_data$total_videos, na.rm = TRUE), 2), "\n")
  cat("- Max Videos per User:", max(duration_data$total_videos, na.rm = TRUE), "\n")
  cat("- Min Videos per User:", min(duration_data$total_videos, na.rm = TRUE), "\n")
} else {
  cat("Video data not available\n")
}
```

## 4. User Video Statistics

```{r user-video-stats, echo=FALSE}
if (file.exists(file.path(data_path, "user_videos_additional_analysis.csv"))) {
  video_stats <- read.csv(file.path(data_path, "user_videos_additional_analysis.csv"))
  
  # Create scatter plot of videos vs field completion
  p5 <- ggplot(video_stats, aes(x = total_videos, y = pct_with_all_fields)) +
    geom_point(alpha = 0.6, color = "purple") +
    geom_smooth(method = "lm", se = TRUE) +
    labs(title = "Total Videos vs Field Completion Rate",
         x = "Total Videos",
         y = "Percentage with All Fields") +
    theme_minimal()
  
  print(p5)
  
  # Summary statistics
  cat("**Video Statistics:**\n")
  cat("- Average Videos per User:", round(mean(video_stats$total_videos, na.rm = TRUE), 2), "\n")
  cat("- Average Field Completion Rate:", round(mean(video_stats$pct_with_all_fields, na.rm = TRUE), 2), "%\n")
  
} else {
  cat("Video statistics data not available\n")
}
```

## 5. Popularity and Engagement Analysis

```{r popularity-engagement, echo=FALSE}
if (file.exists(file.path(data_path, "user_popularity_engagement.csv"))) {
  engagement_data <- read.csv(file.path(data_path, "user_popularity_engagement.csv"))
  
  # Create engagement vs popularity scatter plot
  p6 <- ggplot(engagement_data, aes(x = popularity_score, y = engagement_rate)) +
    geom_point(alpha = 0.6, color = "orange") +
    geom_smooth(method = "lm", se = TRUE) +
    labs(title = "Popularity Score vs Engagement Rate",
         x = "Popularity Score",
         y = "Engagement Rate") +
    theme_minimal()
  
  print(p6)
  
  # Top performers table
  top_performers <- engagement_data %>%
    arrange(desc(engagement_rate)) %>%
    head(10) %>%
    select(username, engagement_rate, popularity_score)
  
  kable(top_performers, caption = "Top 10 Users by Engagement Rate")
  
} else {
  cat("Engagement data not available\n")
}
```

## 6. Field Presence Analysis

```{r field-presence, echo=FALSE}
if (file.exists(file.path(data_path, "video_field_presence_stats.csv"))) {
  field_data <- read.csv(file.path(data_path, "video_field_presence_stats.csv"))
  
  # Create data frame for field presence
  field_summary <- data.frame(
    Field = c("Voice", "Description", "Hashtags", "Hashtag Info", "Mentions"),
    Percentage = c(field_data$voice_percentage, field_data$description_percentage, 
                   field_data$hashtags_percentage, field_data$hashtag_info_percentage, 
                   field_data$mentions_percentage)
  )
  
  # Create field presence bar chart
  p7 <- ggplot(field_summary, aes(x = reorder(Field, Percentage), y = Percentage)) +
    geom_col(fill = "skyblue", alpha = 0.7) +
    coord_flip() +
    labs(title = "Video Field Presence Statistics",
         x = "Field",
         y = "Presence Percentage (%)") +
    theme_minimal()
  
  print(p7)
  
  kable(field_summary, caption = "Field Presence Statistics")
  
} else {
  cat("Field presence data not available\n")
}
```

## 7. Comments Analysis

```{r comments-analysis, echo=FALSE}
if (file.exists(file.path(data_path, "video_comments_stats.csv"))) {
  # The CSV file has a malformed structure, so we'll skip this section for now
  cat("**Comments Statistics:**\n")
  cat("- Comments data available but requires data structure fix\n")
  cat("- This section will be updated once the CSV generation is corrected\n")
  
} else {
  cat("Comments data not available\n")
}
```

## 8. User Bios Analysis

```{r bios-analysis, echo=FALSE}
if (file.exists(file.path(data_path, "user_bios.csv"))) {
  bios_data <- read.csv(file.path(data_path, "user_bios.csv"))
  
  # Calculate bio lengths
  bios_data$bio_length <- nchar(as.character(bios_data$bio_description))
  
  # Create bio length distribution
  p9 <- ggplot(bios_data, aes(x = bio_length)) +
    geom_histogram(bins = 30, fill = "lightblue", alpha = 0.7) +
    labs(title = "Distribution of Bio Lengths",
         x = "Bio Length (characters)",
         y = "Number of Users") +
    theme_minimal()
  
  print(p9)
  
  # Summary statistics
  cat("**Bio Length Statistics:**\n")
  cat("- Mean Length:", round(mean(bios_data$bio_length, na.rm = TRUE), 2), "characters\n")
  cat("- Median Length:", round(median(bios_data$bio_length, na.rm = TRUE), 2), "characters\n")
  cat("- Max Length:", max(bios_data$bio_length, na.rm = TRUE), "characters\n")
  
} else {
  cat("User bios data not available\n")
}
```

## 9. Comprehensive Analysis

```{r comprehensive-analysis, echo=FALSE}
if (file.exists(file.path(data_path, "user_videos_comprehensive_analysis.csv"))) {
  comprehensive_data <- read.csv(file.path(data_path, "user_videos_comprehensive_analysis.csv"))
  
  # Display comprehensive analysis summary
  cat("**Comprehensive Analysis Summary:**\n")
  cat("- Total Influencers Analyzed:", comprehensive_data$total_influencers, "\n")
  cat("- Missing Influencers:", comprehensive_data$missing_influencers, "\n")
  cat("- Total Missing Data Points:", comprehensive_data$total_missing, "\n")
  cat("- Data completeness:", round((1 - comprehensive_data$total_missing / (comprehensive_data$total_influencers * 10)) * 100, 2), "%\n")
  
} else {
  cat("Comprehensive analysis data not available\n")
}
```

## 10. Hashtag Frequencies

```{r hashtag-frequencies-2, echo=FALSE}
unique_path <- file.path(data_path, "tiktok_video_hashtags_unique.csv")
flat_path <- file.path(data_path, "tiktok_video_hashtags_flat.csv")
if (file.exists(unique_path)) {
  tags_unique <- read.csv(unique_path, stringsAsFactors = FALSE) %>%
    arrange(desc(occurrences))
  display <- tags_unique %>% select(hashtag_name, distinct_videos, distinct_users) %>% head(50)
  kable(display, caption = "Top 50 Hashtags by Occurrence (TikTok)")
} else if (file.exists(flat_path)) {
  tags_flat <- read.csv(flat_path, stringsAsFactors = FALSE)
  display <- tags_flat %>%
    group_by(hashtag_name) %>%
    summarise(distinct_videos = n_distinct(video_id), distinct_users = n_distinct(username), .groups = "drop") %>%
    arrange(desc(distinct_videos)) %>% head(50)
  kable(display, caption = "Top 50 Hashtags by Occurrence (TikTok)")
} else {
  cat("Hashtag data not available\n")
}
```

## Sticker Frequencies

```{r sticker-frequencies, echo=FALSE}
unique_path <- file.path(data_path, "tiktok_video_stickers_unique.csv")
if (file.exists(unique_path)) {
  stickers_unique <- read.csv(unique_path, stringsAsFactors = FALSE) %>%
    arrange(desc(occurrences))
  kable(head(stickers_unique, 50), caption = "Top 50 Stickers by Occurrence (TikTok)")
} else {
  cat("Sticker frequency data not available\n")
}
```

## Conclusion

This analysis provides insights into TikTok influencer behavior, engagement patterns, and content characteristics. The data reveals trends in follower distribution, verification status, video performance, and user engagement metrics that can inform content strategy and platform understanding.

---

*Report generated on `r Sys.Date()`*